{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b37fa2-14f3-485b-9c8e-2e43941bfc36",
   "metadata": {},
   "source": [
    "# Financial Literacy Chatbot: Budgeting and Saving Tips.\n",
    "\n",
    "This Jupyter Notebook contains the code and explanation for creating a simple chatbot using Streamlit. The chatbot is designed to answer questions and provide guidance on financial literacy, focusing on budgeting, saving tips, and basic financial planning. By interacting with the chatbot, users can explore practical advice for managing finances effectively.\n",
    "\n",
    "### Project Objectives:\n",
    "1. **Data Preparation**: Preprocess a text file on financial literacy to extract relevant responses for common questions on budgeting and saving.\n",
    "2. **Similarity Matching**: Implement a similarity function that identifies the most relevant advice based on user questions.\n",
    "3. **User Interface**: Build a Streamlit interface for interactive Q&A with the chatbot.\n",
    "\n",
    "### Topic and Source:\n",
    "The chosen topic, **Financial Literacy and Budgeting Tips**, is inspired by timeless financial principles that are widely applicable to individuals seeking to improve their financial health. The primary text source for this project is *\"The Richest Man in Babylon\"* by George S. Clason, available on [Project Gutenberg](https://www.gutenberg.org/). This classic provides foundational insights into personal finance, saving habits, and financial discipline.\n",
    "\n",
    "### Instructions for Use\n",
    "1. **Run the Notebook Cells**: Follow the code cells to load, preprocess, and set up the chatbot.\n",
    "2. **Chatbot Interaction**: Once deployed, the Streamlit interface allows users to input financial questions, receiving practical responses based on principles from *\"The Richest Man in Babylon\"*.\n",
    "3. **Limitations**: This chatbot is a basic informational tool designed to share general budgeting and saving tips and does not replace professional financial advice.\n",
    "\n",
    "*Note: The chatbot operates based on public domain text, providing general guidance on financial wellness and does not constitute personalized financial advice.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c408f74-0175-434f-befb-6626b360f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿“A Classic From  \n",
      "The Diamond’s Mine Library”  \n",
      "The Richest  Man In Babylon \n",
      "1926  \n",
      "George S. Clason\n",
      "1  \n",
      "Brought To You By  \n",
      "http://TheDiamondsMine.com \n",
      "The Richest Man In Babylon  \n",
      "1926  \n",
      "Public Domain Notice  \n",
      "This classic writing compliments of The Diamond’s Mine Online Library. It is  public domain and may be distributed freely. \n",
      "  \n",
      "\n",
      "2  \n",
      "Brought To You By  \n",
      "http://TheDiamondsMine.com \n",
      "Index  \n",
      "About The Author ...................................................... 6 Foreword ................................................................ 7 An Historical Sketch of Babylon ..................................... 8 The Man Who Desired Gold..........................................14 The Richest Man In Babylon.........................................20 Seven Cures For a Lean Purse ......................................30 \n",
      "The First Cure .........................................................34 Start thy purse to fattening.................................................... 34 \n",
      "The Sec\n"
     ]
    }
   ],
   "source": [
    "# Loading the text file.\n",
    "\n",
    "def load_text_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "# Loading and displaying a preview of the text.\n",
    "text_data = load_text_file(\"Clason-RichestManInBabylon.txt\")\n",
    "print(text_data[:1000])  # first 1000 characters for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875cefd2-ceea-4b27-a324-17269f736358",
   "metadata": {},
   "source": [
    "# text processing\n",
    "to remove punctuation, lowercase it, and split it into sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe032db-f480-42cd-ac4b-8e5cf8d2c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/kingoriwangui/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kingoriwangui/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kingoriwangui/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Split text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Lowercase, remove punctuation and stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    cleaned_sentences = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word.isalpha() and word not in stop_words]\n",
    "        cleaned_sentences.append(\" \".join(words))\n",
    "    \n",
    "    return sentences, cleaned_sentences  # Return both original and cleaned versions\n",
    "\n",
    "# Preprocess the loaded text data\n",
    "original_sentences, processed_sentences = preprocess_text(text_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe494b3-dc0b-4159-b39b-74912cb97d21",
   "metadata": {},
   "source": [
    "# Defining the Similarity Function\n",
    "to help find the most relevant response,using cosine similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa48566c-abd6-400c-9607-bdc9dc00a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_most_relevant_sentence(user_query, sentences, processed_sentences):\n",
    "    # Vectorize both user query and text sentences\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([user_query] + processed_sentences)\n",
    "    \n",
    "    # Calculate cosine similarity between the user query and all sentences\n",
    "    similarities = cosine_similarity(vectors[0:1], vectors[1:]).flatten()\n",
    "    \n",
    "    # Find the most similar sentence index\n",
    "    most_similar_index = similarities.argmax()\n",
    "    return sentences[most_similar_index]  # Return original sentence for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d583f9-3996-4daf-afe8-4447ca0b0156",
   "metadata": {},
   "source": [
    "# Defining the Chatbot Function\n",
    "to combine all the components and return a response based on the user’s input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679113f4-002d-4b79-9501-24f09cc8aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_input):\n",
    "    response = get_most_relevant_sentence(user_input, original_sentences, processed_sentences)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1c616-23c2-430b-9c6f-ae833d634f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
